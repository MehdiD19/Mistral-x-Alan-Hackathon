import pandas as pd
import time
from mistralai import Mistral

api_key = 'hspeKPGbJPCvwck1T91QLMIdLWTiEVpK'  # Remplacez par votre clé API
questions_file = '/kaggle/input/mistral-alan-challenge/questions.csv'  # Chemin vers le fichier CSV des questions

df = pd.read_csv(questions_file)
client = Mistral(api_key=api_key)

# Générateur de prompt pour plusieurs questions dans une seule requête
def batch_question_prompt(batch):
    prompt = (
        "Answer the following questions with the letters of the correct answers. "
        "Each question can have multiple answers that are correct. "
        "For each question, your answer must contain only the letters of the answers, separated by commas with no spaces, "
        "in alphabetical order (e.g., 'A,B'). Output the answers for all the questions, one per line.\n\n"
    )
    for idx, row in batch.iterrows():  # Utiliser .iterrows() pour itérer sur les lignes
        prompt += (
            f"Question {idx + 1}: {row['question']}\n"
            f"A: {row['answer_A']}\n"
            f"B: {row['answer_B']}\n"
            f"C: {row['answer_C']}\n"
            f"D: {row['answer_D']}\n"
            f"E: {row['answer_E']}\n\n"
        )
    return prompt

# Fonction pour traiter les batchs
def process_batch(batch):
    prompt = batch_question_prompt(batch)
    chat_response = client.chat.complete(
        model="mistral-large-latest",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.  # Zéro température pour des réponses déterministes
    )
    # Les réponses du modèle seront en ligne par question, donc on peut les diviser par saut de ligne
    return chat_response.choices[0].message.content.splitlines()

# Variables pour stocker les réponses
answers = []

# Définissez la taille du batch (par ex. 5 questions par batch)
batch_size = 7

# Parcourir le DataFrame par batchs
for i in range(0, len(df), batch_size):
    batch = df.iloc[i:i + batch_size]  # Sélectionner un batch de `batch_size` questions
    try:
        batch_answers = process_batch(batch)
        answers.extend(batch_answers)
    except Exception as e:
        print(f"Erreur lors du traitement du batch {i // batch_size}: {str(e)}")
    time.sleep(1)  # Attendez 1 seconde entre les batchs pour éviter les limites de requêtes

# Format de sortie avec exactement 103 lignes
output_df = pd.DataFrame(answers, columns=["Answer"])
output_df.index.name = "id"

# Sauvegarder le fichier de sortie
output_df.to_csv("output.csv")
